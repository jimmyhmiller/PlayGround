use string::string_len;
use string::string_byte_at;
use string::string_slice;
use string::string_eq;
use string::string_concat;

link "c";
extern fn malloc(size: I64) -> RawPointer<I8>;
extern fn ptr_store_i8(p: RawPointer<I8>, off: I64, val: I64) -> I64;
use io::print_str;
use io::print_int;
use io::read_file;
use io::arg_str;
use io::arg_len;
use vec::vec_new;
use vec::vec_len;
use vec::vec_push_tok;
use vec::vec_get_tok;
use vec::Vec;

// ---------------------------------------------------------------------------
// Token types
// ---------------------------------------------------------------------------

enum TokenKind {
    // Literals
    Ident { name: String },
    IntLit { text: String },
    FloatLit { text: String },
    StrLit { text: String },
    CharLit { value: I64 },
    // Keywords
    KwFn {},
    KwStruct {},
    KwEnum {},
    KwLet {},
    KwMut {},
    KwIf {},
    KwElse {},
    KwWhile {},
    KwMatch {},
    KwReturn {},
    KwBreak {},
    KwContinue {},
    KwTrue {},
    KwFalse {},
    KwExtern {},
    KwUse {},
    KwModule {},
    KwLink {},
    // Punctuation
    LParen {},
    RParen {},
    LBrace {},
    RBrace {},
    LBracket {},
    RBracket {},
    Comma {},
    Semi {},
    Colon {},
    ColonColon {},
    Arrow {},
    FatArrow {},
    Dot {},
    // Operators
    Plus {},
    Minus {},
    Star {},
    Slash {},
    Percent {},
    Eq {},
    EqEq {},
    Bang {},
    BangEq {},
    Lt {},
    LtEq {},
    Gt {},
    GtEq {},
    AndAnd {},
    OrOr {},
    // Special
    Ellipsis {},
    Eof {}
}

struct Token {
    kind: TokenKind,
    start: I64,
    end: I64
}

// ---------------------------------------------------------------------------
// Lexer state
// ---------------------------------------------------------------------------

struct Lexer {
    source: String,
    pos: I64,
    len: I64
}

fn new_lexer(source: String) -> Lexer {
    Lexer { source: source, pos: 0, len: string_len(source) }
}

// Peek at current byte, returns -1 at EOF.
fn peek(lex: Lexer) -> I64 {
    if lex.pos >= lex.len {
        0 - 1
    } else {
        string_byte_at(lex.source, lex.pos)
    }
}

// Peek at next byte (pos+1), returns -1 at EOF.
fn peek2(lex: Lexer) -> I64 {
    let next: I64 = lex.pos + 1;
    if next >= lex.len {
        0 - 1
    } else {
        string_byte_at(lex.source, next)
    }
}

// Advance one byte and return it. Returns -1 if already at EOF.
fn advance(lex: Lexer) -> I64 {
    let ch: I64 = peek(lex);
    if ch >= 0 {
        lex.pos = lex.pos + 1;
    };
    ch
}

// ---------------------------------------------------------------------------
// Character classification helpers
// ---------------------------------------------------------------------------

fn is_alpha(ch: I64) -> Bool {
    (ch >= 'a' && ch <= 'z') || (ch >= 'A' && ch <= 'Z') || ch == '_'
}

fn is_digit(ch: I64) -> Bool {
    ch >= '0' && ch <= '9'
}

fn is_alnum(ch: I64) -> Bool {
    is_alpha(ch) || is_digit(ch)
}

fn is_whitespace(ch: I64) -> Bool {
    ch == ' ' || ch == '\t' || ch == '\n' || ch == '\r'
}

// ---------------------------------------------------------------------------
// Skip whitespace and comments
// ---------------------------------------------------------------------------

fn skip_whitespace_and_comments(lex: Lexer) -> Unit {
    let mut cont: Bool = true;
    while cont {
        let ch: I64 = peek(lex);
        if is_whitespace(ch) {
            advance(lex);
        } else {
            if ch == '/' {
                let ch2: I64 = peek2(lex);
                if ch2 == '/' {
                    // Line comment: skip to end of line
                    advance(lex);
                    advance(lex);
                    while peek(lex) >= 0 && peek(lex) != '\n' {
                        advance(lex);
                    };
                } else {
                    if ch2 == '*' {
                        // Block comment: skip to */
                        advance(lex);
                        advance(lex);
                        let mut depth: I64 = 1;
                        while depth > 0 && peek(lex) >= 0 {
                            let c: I64 = peek(lex);
                            let c2: I64 = peek2(lex);
                            if c == '/' && c2 == '*' {
                                advance(lex);
                                advance(lex);
                                depth = depth + 1;
                            } else {
                                if c == '*' && c2 == '/' {
                                    advance(lex);
                                    advance(lex);
                                    depth = depth - 1;
                                } else {
                                    advance(lex);
                                }
                            };
                        };
                    } else {
                        cont = false;
                    }
                }
            } else {
                cont = false;
            }
        };
    };
    ()
}

// ---------------------------------------------------------------------------
// Keyword lookup
// ---------------------------------------------------------------------------

fn keyword_or_ident(text: String) -> TokenKind {
    if string_eq(text, "fn") == 1 { return TokenKind::KwFn {}; };
    if string_eq(text, "struct") == 1 { return TokenKind::KwStruct {}; };
    if string_eq(text, "enum") == 1 { return TokenKind::KwEnum {}; };
    if string_eq(text, "let") == 1 { return TokenKind::KwLet {}; };
    if string_eq(text, "mut") == 1 { return TokenKind::KwMut {}; };
    if string_eq(text, "if") == 1 { return TokenKind::KwIf {}; };
    if string_eq(text, "else") == 1 { return TokenKind::KwElse {}; };
    if string_eq(text, "while") == 1 { return TokenKind::KwWhile {}; };
    if string_eq(text, "match") == 1 { return TokenKind::KwMatch {}; };
    if string_eq(text, "return") == 1 { return TokenKind::KwReturn {}; };
    if string_eq(text, "break") == 1 { return TokenKind::KwBreak {}; };
    if string_eq(text, "continue") == 1 { return TokenKind::KwContinue {}; };
    if string_eq(text, "true") == 1 { return TokenKind::KwTrue {}; };
    if string_eq(text, "false") == 1 { return TokenKind::KwFalse {}; };
    if string_eq(text, "extern") == 1 { return TokenKind::KwExtern {}; };
    if string_eq(text, "use") == 1 { return TokenKind::KwUse {}; };
    if string_eq(text, "module") == 1 { return TokenKind::KwModule {}; };
    if string_eq(text, "link") == 1 { return TokenKind::KwLink {}; };
    TokenKind::Ident { name: text }
}

// ---------------------------------------------------------------------------
// Lex a single token
// ---------------------------------------------------------------------------

fn lex_ident(lex: Lexer) -> Token {
    let start: I64 = lex.pos;
    while is_alnum(peek(lex)) {
        advance(lex);
    };
    let text: String = string_slice(lex.source, start, lex.pos);
    Token { kind: keyword_or_ident(text), start: start, end: lex.pos }
}

fn lex_number(lex: Lexer) -> Token {
    let start: I64 = lex.pos;
    while is_digit(peek(lex)) || peek(lex) == '_' {
        advance(lex);
    };
    // Check for float
    if peek(lex) == '.' && is_digit(peek2(lex)) {
        advance(lex); // skip '.'
        while is_digit(peek(lex)) || peek(lex) == '_' {
            advance(lex);
        };
        let text: String = string_slice(lex.source, start, lex.pos);
        Token { kind: TokenKind::FloatLit { text: text }, start: start, end: lex.pos }
    } else {
        let text: String = string_slice(lex.source, start, lex.pos);
        Token { kind: TokenKind::IntLit { text: text }, start: start, end: lex.pos }
    }
}

fn lex_string(lex: Lexer) -> Token {
    let start: I64 = lex.pos;
    let content_start: I64 = lex.pos + 1;  // Position after opening quote
    advance(lex); // skip opening "

    // First pass: count characters and find end quote
    let mut escaped: Bool = false;
    let mut cont: Bool = true;
    let mut result_len: I64 = 0;

    while cont {
        let ch: I64 = peek(lex);
        if ch < 0 {
            cont = false;
        } else {
            if escaped {
                result_len = result_len + 1;  // Escape sequence becomes one char
                advance(lex);
                escaped = false;
            } else {
                if ch == '\\' {
                    advance(lex);
                    escaped = true;
                } else {
                    if ch == '"' {
                        advance(lex);
                        cont = false;
                    } else {
                        result_len = result_len + 1;
                        advance(lex);
                    }
                }
            };
        };
    };

    // Second pass: build result string with escapes processed
    let buf: RawPointer<I8> = malloc(result_len + 1);
    lex.pos = content_start;  // Reset to start of string content
    let mut write_pos: I64 = 0;
    escaped = false;
    cont = true;

    while cont {
        let ch: I64 = peek(lex);
        if ch < 0 {
            cont = false;
        } else {
            if escaped {
                // Process escape sequence
                let esc_char: I64 = if ch == 'n' {
                    10  // newline
                } else {
                    if ch == 't' {
                        9  // tab
                    } else {
                        if ch == 'r' {
                            13  // carriage return
                        } else {
                            if ch == '\\' {
                                92  // backslash
                            } else {
                                if ch == '"' {
                                    34  // quote
                                } else {
                                    ch  // unknown escape, keep as-is
                                }
                            }
                        }
                    }
                };
                ptr_store_i8(buf, write_pos, esc_char);
                write_pos = write_pos + 1;
                advance(lex);
                escaped = false;
            } else {
                if ch == '\\' {
                    advance(lex);
                    escaped = true;
                } else {
                    if ch == '"' {
                        advance(lex);
                        cont = false;
                    } else {
                        ptr_store_i8(buf, write_pos, ch);
                        write_pos = write_pos + 1;
                        advance(lex);
                    }
                }
            };
        };
    };

    ptr_store_i8(buf, write_pos, 0);  // null terminator
    Token { kind: TokenKind::StrLit { text: buf }, start: start, end: lex.pos }
}

fn lex_char(lex: Lexer) -> Token {
    let start: I64 = lex.pos;
    advance(lex); // skip opening '
    let ch: I64 = peek(lex);
    let value: I64 = if ch == '\\' {
        advance(lex); // skip backslash
        let esc: I64 = advance(lex);
        if esc == 'n' {
            '\n'
        } else {
            if esc == 't' {
                '\t'
            } else {
                if esc == 'r' {
                    '\r'
                } else {
                    if esc == '\\' {
                        '\\'
                    } else {
                        if esc == '\'' {
                            '\''
                        } else {
                            if esc == '0' {
                                0
                            } else {
                                // \xNN hex escape
                                if esc == 'x' {
                                    let h1: I64 = hex_digit(advance(lex));
                                    let h2: I64 = hex_digit(advance(lex));
                                    h1 * 16 + h2
                                } else {
                                    esc
                                }
                            }
                        }
                    }
                }
            }
        }
    } else {
        advance(lex)
    };
    // Skip closing '
    if peek(lex) == '\'' {
        advance(lex);
    };
    Token { kind: TokenKind::CharLit { value: value }, start: start, end: lex.pos }
}

fn hex_digit(ch: I64) -> I64 {
    if ch >= '0' && ch <= '9' {
        ch - '0'
    } else {
        if ch >= 'a' && ch <= 'f' {
            ch - 'a' + 10
        } else {
            if ch >= 'A' && ch <= 'F' {
                ch - 'A' + 10
            } else {
                0
            }
        }
    }
}

// ---------------------------------------------------------------------------
// Main lex_token: dispatch on first character
// ---------------------------------------------------------------------------

fn lex_token(lex: Lexer) -> Token {
    skip_whitespace_and_comments(lex);

    let start: I64 = lex.pos;
    let ch: I64 = peek(lex);

    // EOF
    if ch < 0 {
        return Token { kind: TokenKind::Eof {}, start: start, end: start };
    };

    // Identifiers and keywords
    if is_alpha(ch) {
        return lex_ident(lex);
    };

    // Numbers
    if is_digit(ch) {
        return lex_number(lex);
    };

    // String literal
    if ch == '"' {
        return lex_string(lex);
    };

    // Char literal
    if ch == '\'' {
        return lex_char(lex);
    };

    // Two-character tokens first
    let ch2: I64 = peek2(lex);

    if ch == ':' && ch2 == ':' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::ColonColon {}, start: start, end: lex.pos };
    };
    if ch == '-' && ch2 == '>' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::Arrow {}, start: start, end: lex.pos };
    };
    if ch == '=' && ch2 == '>' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::FatArrow {}, start: start, end: lex.pos };
    };
    if ch == '=' && ch2 == '=' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::EqEq {}, start: start, end: lex.pos };
    };
    if ch == '!' && ch2 == '=' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::BangEq {}, start: start, end: lex.pos };
    };
    if ch == '<' && ch2 == '=' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::LtEq {}, start: start, end: lex.pos };
    };
    if ch == '>' && ch2 == '=' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::GtEq {}, start: start, end: lex.pos };
    };
    if ch == '&' && ch2 == '&' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::AndAnd {}, start: start, end: lex.pos };
    };
    if ch == '|' && ch2 == '|' {
        advance(lex); advance(lex);
        return Token { kind: TokenKind::OrOr {}, start: start, end: lex.pos };
    };

    // Ellipsis: ...
    if ch == '.' && ch2 == '.' {
        let ch3: I64 = if lex.pos + 2 < lex.len { string_byte_at(lex.source, lex.pos + 2) } else { 0 - 1 };
        if ch3 == '.' {
            advance(lex); advance(lex); advance(lex);
            return Token { kind: TokenKind::Ellipsis {}, start: start, end: lex.pos };
        };
    };

    // Single-character tokens
    advance(lex);
    let kind: TokenKind = if ch == '(' {
        TokenKind::LParen {}
    } else { if ch == ')' {
        TokenKind::RParen {}
    } else { if ch == '{' {
        TokenKind::LBrace {}
    } else { if ch == '}' {
        TokenKind::RBrace {}
    } else { if ch == '[' {
        TokenKind::LBracket {}
    } else { if ch == ']' {
        TokenKind::RBracket {}
    } else { if ch == ',' {
        TokenKind::Comma {}
    } else { if ch == ';' {
        TokenKind::Semi {}
    } else { if ch == ':' {
        TokenKind::Colon {}
    } else { if ch == '.' {
        TokenKind::Dot {}
    } else { if ch == '+' {
        TokenKind::Plus {}
    } else { if ch == '-' {
        TokenKind::Minus {}
    } else { if ch == '*' {
        TokenKind::Star {}
    } else { if ch == '/' {
        TokenKind::Slash {}
    } else { if ch == '%' {
        TokenKind::Percent {}
    } else { if ch == '=' {
        TokenKind::Eq {}
    } else { if ch == '!' {
        TokenKind::Bang {}
    } else { if ch == '<' {
        TokenKind::Lt {}
    } else { if ch == '>' {
        TokenKind::Gt {}
    } else {
        // Unknown character - just produce an Ident with the char
        TokenKind::Ident { name: string_slice(lex.source, start, lex.pos) }
    } } } } } } } } } } } } } } } } } } };

    Token { kind: kind, start: start, end: lex.pos }
}

// ---------------------------------------------------------------------------
// Lex all tokens
// ---------------------------------------------------------------------------

fn lex_all(source: String) -> Vec {
    let lex: Lexer = new_lexer(source);
    let tokens: Vec = vec_new();
    let mut done: Bool = false;
    while !done {
        let tok: Token = lex_token(lex);
        vec_push_tok(tokens, tok);
        match tok.kind {
            TokenKind::Eof {} => {
                done = true;
            },
            _ => { () }
        };
    };
    tokens
}

// ---------------------------------------------------------------------------
// Token display (for debugging)
// ---------------------------------------------------------------------------

fn token_kind_name(kind: TokenKind) -> String {
    match kind {
        TokenKind::Ident { name } => string_concat("Ident(", string_concat(name, ")")),
        TokenKind::IntLit { text } => string_concat("Int(", string_concat(text, ")")),
        TokenKind::FloatLit { text } => string_concat("Float(", string_concat(text, ")")),
        TokenKind::StrLit { text } => string_concat("Str(\"", string_concat(text, "\")")),
        TokenKind::CharLit { value } => "Char",
        TokenKind::KwFn {} => "fn",
        TokenKind::KwStruct {} => "struct",
        TokenKind::KwEnum {} => "enum",
        TokenKind::KwLet {} => "let",
        TokenKind::KwMut {} => "mut",
        TokenKind::KwIf {} => "if",
        TokenKind::KwElse {} => "else",
        TokenKind::KwWhile {} => "while",
        TokenKind::KwMatch {} => "match",
        TokenKind::KwReturn {} => "return",
        TokenKind::KwBreak {} => "break",
        TokenKind::KwContinue {} => "continue",
        TokenKind::KwTrue {} => "true",
        TokenKind::KwFalse {} => "false",
        TokenKind::KwExtern {} => "extern",
        TokenKind::KwUse {} => "use",
        TokenKind::KwModule {} => "module",
        TokenKind::KwLink {} => "link",
        TokenKind::LParen {} => "(",
        TokenKind::RParen {} => ")",
        TokenKind::LBrace {} => "{",
        TokenKind::RBrace {} => "}",
        TokenKind::LBracket {} => "[",
        TokenKind::RBracket {} => "]",
        TokenKind::Comma {} => ",",
        TokenKind::Semi {} => ";",
        TokenKind::Colon {} => ":",
        TokenKind::ColonColon {} => "::",
        TokenKind::Arrow {} => "->",
        TokenKind::FatArrow {} => "=>",
        TokenKind::Dot {} => ".",
        TokenKind::Plus {} => "+",
        TokenKind::Minus {} => "-",
        TokenKind::Star {} => "*",
        TokenKind::Slash {} => "/",
        TokenKind::Percent {} => "%",
        TokenKind::Eq {} => "=",
        TokenKind::EqEq {} => "==",
        TokenKind::Bang {} => "!",
        TokenKind::BangEq {} => "!=",
        TokenKind::Lt {} => "<",
        TokenKind::LtEq {} => "<=",
        TokenKind::Gt {} => ">",
        TokenKind::GtEq {} => ">=",
        TokenKind::AndAnd {} => "&&",
        TokenKind::OrOr {} => "||",
        TokenKind::Ellipsis {} => "...",
        TokenKind::Eof {} => "EOF"
    }
}

fn token_kind_tag(kind: TokenKind) -> I64 {
    match kind {
        TokenKind::Ident { name } => 1,
        TokenKind::IntLit { text } => 2,
        TokenKind::FloatLit { text } => 3,
        TokenKind::StrLit { text } => 4,
        TokenKind::CharLit { value } => 5,
        TokenKind::KwFn {} => 6,
        TokenKind::KwStruct {} => 7,
        TokenKind::KwEnum {} => 8,
        TokenKind::KwLet {} => 9,
        TokenKind::KwMut {} => 10,
        TokenKind::KwIf {} => 11,
        TokenKind::KwElse {} => 12,
        TokenKind::KwWhile {} => 13,
        TokenKind::KwMatch {} => 14,
        TokenKind::KwReturn {} => 15,
        TokenKind::KwBreak {} => 16,
        TokenKind::KwContinue {} => 17,
        TokenKind::KwTrue {} => 18,
        TokenKind::KwFalse {} => 19,
        TokenKind::KwExtern {} => 20,
        TokenKind::KwUse {} => 21,
        TokenKind::KwModule {} => 22,
        TokenKind::KwLink {} => 53,
        TokenKind::LParen {} => 23,
        TokenKind::RParen {} => 24,
        TokenKind::LBrace {} => 25,
        TokenKind::RBrace {} => 26,
        TokenKind::LBracket {} => 27,
        TokenKind::RBracket {} => 28,
        TokenKind::Comma {} => 29,
        TokenKind::Semi {} => 30,
        TokenKind::Colon {} => 31,
        TokenKind::ColonColon {} => 32,
        TokenKind::Arrow {} => 33,
        TokenKind::FatArrow {} => 34,
        TokenKind::Dot {} => 35,
        TokenKind::Plus {} => 36,
        TokenKind::Minus {} => 37,
        TokenKind::Star {} => 38,
        TokenKind::Slash {} => 39,
        TokenKind::Percent {} => 40,
        TokenKind::Eq {} => 41,
        TokenKind::EqEq {} => 42,
        TokenKind::Bang {} => 43,
        TokenKind::BangEq {} => 44,
        TokenKind::Lt {} => 45,
        TokenKind::LtEq {} => 46,
        TokenKind::Gt {} => 47,
        TokenKind::GtEq {} => 48,
        TokenKind::AndAnd {} => 49,
        TokenKind::OrOr {} => 50,
        TokenKind::Ellipsis {} => 51,
        TokenKind::Eof {} => 52
    }
}

fn print_token(tok: Token) -> Unit {
    print_str(token_kind_name(tok.kind));
    ()
}

// ---------------------------------------------------------------------------
// Main: lex a file passed as argument and print tokens
// ---------------------------------------------------------------------------

fn main() -> I64 {
    if arg_len() < 1 {
        print_str("usage: lexer <file>");
        return 1;
    };
    let path: String = arg_str(0);
    let source: String = read_file(path);
    let tokens: Vec = lex_all(source);
    let count: I64 = vec_len(tokens);
    let mut i: I64 = 0;
    while i < count {
        let tok: Token = vec_get_tok(tokens, i);
        print_token(tok);
        i = i + 1;
    };
    print_str(string_concat("Total tokens: ", ""));
    print_int(count);
    0
}
